Design Ideas

Individuals and Teams of individuals tackle data problems and submit solutions on Kaggle

How do you tackle a data problem?
	They give you raw data
	You do some magic via a PIPELINE(PL)
	Prediction comes out.

What is the PIPELINE and how do we go about making one?
	PIPELINE in Theory
		STAGES
			FEATUREGENERATOR
			FEATUREMANIPULATOR
			PARAMETERFINDER
			PREDICTIONALGO
			ENSEMBLE
	STAGES do the following
		RAW DATA             ==FEATUREGENERATOR   => FEATURED DATA
		FEATURED DATA        ==FEATUREMANIPULATOR => BETTER FEATURED DATA

		FEATURED DATA        ==PARAMETERFINDER    => PARAMETERS
		BETTER FEATURED DATA ==PARAMETERFINDER    => PARAMETERS

		FD + PARAMETERS      ==PREDICTIONALGO     => PREDICTION
		BFD + PARAMETERS     ==PREDICTIONALGO     => PREDICTION

		PREDICTION(S)        ==ENSEMBLE           => BETTER PREDICTION

Thats all good and dandy, but we could just write these and use them for given project.  Why do we need to track them?
	In order to understand the need for tracking we have to go back to People and Teams

BACK TO PEOPLE AND TEAMS
So these people....what about them?
	Remember that working on a pipeline takes time and a lot of thought!
	1) People want to feel accomplished(want to know what they have done to show it to people)
	2) People want to only make forward progress(are lazy and done want to write things more than once)

So what can we do about those People Problems?
	For PROBLEM 1, we can help them keep track of their
		Contributions to:
			PROBLEMS
			PIPELINES
			STAGES of PL
		How the PL performed

	For PROBLEM 2, we can
		Help make the code they write as modular as possible
		Calculate a weighted average on how we thing the modules helped the overall pipeline perform

SO HOW DO WE ADDRESS THE ABOVE PROBLEMS?

First we look at classes
	The independent classes are 
		PEOPLE
		PROBLEMS(KAGGLE COMPETITIONS)
		PIPELINES
		PIPELINE COMPONENTS
	They behave as described below
		PEOPLE
			Develop 
				PIPELINES
				PIPELINE COMPONENTS
		PROBLEMS
			Are given to us by the Kaggle Gods lol
		PIPELINES
			Produce Predictions for PROBLEMS
			Have many PL COMPONENTS
		PIPELINE COMPONENTS
			can be used in multiple PIPELINES
	The above classes will help us compartmentalize the different parts

Second we look at repository structure
	Kaggle
		PROBLEMS
			Problem_name
				input
				intermediary
				output
				pipelines
				logs
		PL COMPONENTS
			PL class
			COMPONENT CLASSES
			logs
		PEOPLE
			logs
	The above repository structure will help us minimize the amount of brainpower the user has to use up with file management. This includes finding the latest submission or saving intermediary files

I guess thats cool but the above help to make code easier to code, but code is harder to read than text, and you cant really compile statistics and stuff from code

I see what you mean, but I have left the best for last!
The above structures help facilitate xml loggging!!!!!

If you want to know how we plan on creating logs and managing them then you can read on, otherwise just wait for the movie to come out. lol

Pipeline logs are stored in the PROBLEM_NAME/log folder
They are generated when a submission is created, by the PL


/** 
	Specifics have yet to be figured out how to derive PEOPLE and COMPONENTS
	Logs in the following folders
		PEOPLE
		COMPONENTS
Are the result of aggregation entries from the Problem_name folder logs.
**/

EXAMPLE CASES
	Starting a New Problem
		Make a directory with its name
		Place given data in the "input" folder
		Load a sample response to the output folder (will be used for formatting of all gernated submissions)
		Copy template Pipeline
		Get to work!!!
	Working on a Pipeline
		Add componenets, and add provide your id to track contributions
		If you want to run a pipeline => pl.submit = true
			(The default is pl.submit = false)
		pl class will check for previous running of identical pipelines to prevent redundancy.
		If you are about to make a submission => pl.state = "final"
			(this is useful for post analysis)(We might ad F Final and W working  to the name)
	New Person Joing the Repository.
		Go to the PEOPLE directory
			In the file id_map: provide an id, and your name
				(Your id will be used to map your name in reports and other log analysis)
	Starting a New Pipeline
		Copy PL_Template from root directory(ensures environment settings)
		Construct based on components
			-Components are based in the PL_COMPONENTS file and are developed in a generic fashion to provide portability
		Set pl.submit= Ture when you are ready to submit.
			Script will ask for the result of the submission before writing it to the log.
	Want to copy pipeline from other Project
		Just Copy and paste! Should be completely portable!
	What happens to intermediary files
		They are deleted when pipeline set to final is run(might change this default or add the option to keep_all_files = true, default false)
	Will multiple intermediary files or output files be created?
		No because the function will search for a file before creating it.
		(make a class, that each one will inherit from)
	What if I want to make a pipeline in another language?
		All it needs to do is to log in the format provided(format might change to xml.)




