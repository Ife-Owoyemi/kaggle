Design Ideas

Individuals and Teams of individuals tackel data problems and submit solutions on Kaggle

How do you tackle a data problem?

They give you raw data

You do some magic via a PIPELINE(PL)

Prediction comes out.

What is the PIPELINE and how do we go about making one?

PIPELINE in Theory
	STAGES
		FEATUREGENERATOR
		FEATUREMANIPULATOR
		PARAMETERFINDER
		PREDICTIONALGO
		ENSEMBLE



RAW DATA             ==FEATUREGENERATOR  => FEATURED DATA
FEATURED DATA        ==FEATUREMANIPULATOR=> BETTER FEATURED DATA

FEATURED DATA        ==PARAMETERFINDER   => PARAMETERS
OR
BETTER FEATURED DATA ==PARAMETERFINDER   => PARAMETERS

FD + PARAMETERS      ==PREDICTIONALGO    => PREDICTION
OR
BFD + PARAMETERS     ==PREDICTIONALGO    => PREDICTION

PREDICTION(S)        ==ENSEMBLE          => BETTER PREDICTION


Back to People and Teams

When they work on a pipeline they expect recognition

For their resumes they care about:
	Contributions to:
		PROBLEMS
		PIPELINES
		STAGES of PL
	How the PL performed

For future work they care about:
	How the methods for each stage did in general
	Stuff like that about performance.

So how do we address the above situation?
First we look at classes

	The independent classes are 
		PEOPLE
		PROBLEMS
		PIPELINES
		PIPELINE COMPONENTS
	They behave as described below
		PEOPLE
			Develop 
				PIPELINES
				PIPELINE COMPONENTS
		PROBLEMS
		PIPELINES
			Produce Predictions for PROBLEMS
			Have many PL COMPONENTS
		PIPELINE COMPONENTS
			can be used in multiple PIPELINES

Second we look at repository structure
	Kaggle
		PROBLEMS
			Problem_name
				input
				intermediary
				output
				pipelines
				logs
		PL COMPONENTS
			PL class
			COMPONENT CLASSES
			logs
		PEOPLE
			logs

Third, how does logging work?

Elementary logs are stored in the Problem_name folder
They are generated by PL COMPONENTS when the PL is used to create a prediction that is submitted.
Logs in the following folders
	PEOPLE
	COMPONENTS
Are the result of aggregation entries from the Problem_name folder logs.

EXAMPLE CASES
	Starting a New Problem
		Make a directory with its name
		Place given data in the "input" folder
		Load a sample response to the output folder (will be used for formatting of all gernated submissions)
		Copy template Pipeline
		Get to work!!!
	Working on a Pipeline
		Add componenets, and add provide your id to track contributions
		If you want to run a pipeline => pl.submit = true
			(The default is pl.submit = false)
		pl class will check for previous running of identical pipelines to prevent redundancy.
		If you are about to make a submission => pl.state = "final"
			(this is useful for post analysis)(We might ad F Final and W working  to the name)
	New Person Joing the Repository.
		Go to the PEOPLE directory
			In the file id_map: provide an id, and your name
				(Your id will be used to map your name in reports and other log analysis)
	Starting a New Pipeline
		Copy PL_Template from root directory(ensures environment settings)
		Construct based on components
			-Components are based in the PL_COMPONENTS file and are developed in a generic fashion to provide portability
		Set pl.submit= Ture when you are ready to submit.
			Script will ask for the result of the submission before writing it to the log.
	Want to copy pipeline from other Project
		Just Copy and paste! Should be completely portable!
	What happens to intermediary files
		They are deleted when pipeline set to final is run(might change this default or add the option to keep_all_files = true, default false)
	Will multiple intermediary files or output files be created?
		No because the function will search for a file before creating it.
		(make a class, that each one will inherit from)
	What if I want to make a pipeline in another language?
		All it needs to do is to log in the format provided(format might change to xml.)




